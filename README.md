# Crossref Citation Check Skill

This repository distributes the `$crossref-citation-check` skill for agent workflows (VS Code GitHub Copilot Agent and ChatGPT Codex).

This skill was generated by **Murat Karakaya**.

## Why This Skill Exists

When writing scientific papers, AI tools can hallucinate bibliography details:
- wrong DOI
- wrong year
- wrong journal, volume, issue, or pages
- incomplete or incorrect author list

This skill validates references against Crossref and returns correction-ready metadata.

## 30-Second Quick Start

Follow these copy-paste steps to get started locally and to run the checker on a sample file.

```powershell
git clone https://github.com/kmkarakaya/crossref-citation-check.git
cd crossref-citation-check

# (optional) install the skill into your Codex/Agent skills folder:
# mkdir -p ~/.codex/skills/crossref-citation-check
# cp -r .github/skills/crossref-citation-check ~/.codex/skills/crossref-citation-check

# Run the checker directly on the included sample `bib.tex` (replace email):
python .github/skills/crossref-citation-check/crossref_checker.py -i bib.tex -o refs_results.json -e you@example.com
```

Quick agent prompt (copy-paste):
- Use `Use $crossref-citation-check to validate bib.tex and save the report to refs_results.json.` in your agent chat to run the skill.

## Repository Structure

```text
.
|-- .github/
|   `-- skills/
|       `-- crossref-citation-check/
|           |-- SKILL.md
|           `-- crossref_checker.py
|-- bib.tex
|-- refs.txt
|-- refs.md
|-- citations.json
`-- citations.csv
```

## Skill Files

The distributable skill files are:
- `.github/skills/crossref-citation-check/SKILL.md`
- `.github/skills/crossref-citation-check/crossref_checker.py`

## Sample Files (For Testing)

This repo includes sample references in multiple formats:
- `bib.tex`
- `refs.txt`
- `refs.md`
- `citations.json`
- `citations.csv`

## Install and Use in ChatGPT Codex

1. Download or clone this repository.
2. Copy `.github/skills/crossref-citation-check/` into your Codex skills directory as `~/.codex/skills/crossref-citation-check/`.
3. Confirm the target folder contains:
   - `SKILL.md`
   - `crossref_checker.py`
4. Open Codex chat and invoke the skill by name.

Prompt samples:
- `Use $crossref-citation-check to validate bib.tex and report corrected metadata.`
- `Run $crossref-citation-check on citations.json and save output to refs_results.json.`
- `Use $crossref-citation-check on refs.txt and list unresolved citations.`

## Install and Use in VS Code GitHub Copilot Agent

1. Open this repository in VS Code.
2. Sign in to GitHub Copilot.
3. Open Copilot Chat and switch to Agent mode.
4. Ask the agent to use the skill in `.github/skills/crossref-citation-check/`.

Prompt samples:
- `Use the crossref-citation-check skill to validate refs.md and return field-level corrections.`
- `Use crossref-citation-check on citations.csv and output match_found/no_likely_match/no_match for each item.`
- `Use crossref-citation-check on bib.tex and update incorrect DOI, year, volume, issue, and pages.`

## Prompt Patterns (Do and Don't)

Do:
- `Use $crossref-citation-check on bib.tex and save results to refs_results.json.`
- `Validate citations.json and include field-level provided vs crossref differences.`

Don't:
- `Check my references.`  
- `Fix this bibliography somehow.`

## Supported Input Formats

- `.json`
- `.csv`
- `.txt`
- `.md`
- `.tex`
- `.bib`

## Expected Output

For each citation, the skill reports:
- `status`: `match_found`, `no_likely_match`, or `no_match`
- `matched_by`: `doi` or `title` (if matched)
- `comparison`: field-level values with `provided`, `crossref`, and `match`
- corrected values for mismatched fields

### Minimal Output Schema

```json
{
  "article": {
    "title": "string",
    "authors": ["string"],
    "journal": "string",
    "volume": "string|null",
    "issue": "string|null",
    "pages": "string|null",
    "year": "string|null",
    "doi": "string|null",
    "url": "string|null"
  },
  "status": "match_found|no_likely_match|no_match",
  "matched_by": "doi|title",
  "title_score": 0.0,
  "comparison": {},
  "error": "string"
}
```

### What Good Output Looks Like

`match_found` example:
- DOI and title match Crossref
- year, volume, pages corrected from Crossref

`no_likely_match` example:
- top candidate exists but similarity is below threshold
- citation should be manually verified with DOI, full title, and author list

## End-to-End Demo

1. Use sample input `bib.tex`.
2. Send this prompt:
   - `Use $crossref-citation-check on bib.tex and save output to refs_results.json.`
3. Open `refs_results.json`.
4. For each `match_found`, apply corrected fields to your bibliography.
5. For `no_likely_match` and `no_match`, verify manually and rerun.

## Direct Script Usage (Optional)

If you want to run the checker directly from the command line, copy one of these examples and replace the paths and email address as needed.

```powershell
# Basic run (outputs JSON report):
python .github/skills/crossref-citation-check/crossref_checker.py -i bib.tex -o refs_results.json -e you@example.com

# Stricter title matching:
python .github/skills/crossref-citation-check/crossref_checker.py -i bib.tex -o refs_results.json -e you@example.com --title-threshold 0.90
```

## Limitations

- Crossref may not contain every publication.
- Some sources have incomplete metadata in Crossref.
- Title-only matching can produce false positives if wording is generic.
- Non-ASCII author names may need normalization depending on source encoding.

## Troubleshooting

- Python not found:
  - install Python 3 and retry with `python --version`
- Network issues or API timeouts:
  - retry later and ensure internet access is available
- Poor matches in free-text input:
  - use structured `citations.json` or `citations.csv`
- Repeated `no_likely_match`:
  - provide DOI directly in the input

## Compatibility

| Environment | Status |
|---|---|
| Windows + PowerShell | Tested |
| VS Code GitHub Copilot Agent | Supported |
| ChatGPT Codex (local skills) | Supported |
| Direct Python script execution | Supported |

## Contributing

Contributions are welcome.

Suggested improvements:
- better parser robustness for noisy free-text references
- improved author-name normalization
- additional test fixtures for edge-case citation formats

## License

No license file is currently included in this repository.
Add a `LICENSE` file before broader redistribution if needed.
